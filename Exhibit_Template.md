# **Exhibit:** 

### **Purpose**

To demonstrate a failure mode where a language model:

*   
*   
* 

Model Information:  
\*\*Model:\*\* :    
\*\*Variant / Quant:\*\* :    
\*\*Environment:\*\* :    
\*\*Date:\*\* :

---

## **Prompt Under Test**

“\[unconstrained prompt\]”

**Variant with explicit constraint:**

“\[constrained prompt\]”

---

## **Expected Correct Behavior**

A grounded model should answer from the assistant’s role:

*   
* 

---

## **Observed Model Behavior**

### **Internal Reasoning (Correct/Incorrect)**

The model’s internal reasoning \[correctly / incorrectly\] identifies that:

* 

---

### **Final Answer (Correct/Incorrect)**

Unconstrained prompt:

“\[model answer\]”

Constrained prompt:

	"\[model answer\]"

---

## **Failure Analysis**

### **1\.** 

* A  
* B  
* C  
* D

---

* 

---

## **Classification of Failure Modes**

* Deictic / Pronoun Reference Failure

* Role Boundary Violation

* Assumption Injection

* Question Substitution

* Post-Deliberation Semantic Regression

* Epistemic Overconfidence

---

## **Trust & Safety Relevance**

This failure mode is significant because:

*   
*   
* 

This is especially dangerous in contexts involving:

*   
* 

---

## **Key Insight**

